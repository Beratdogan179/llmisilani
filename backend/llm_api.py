import os
import json
import re
import time
import sys
from datetime import datetime
from tempfile import NamedTemporaryFile
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any
import uvicorn

# --- KÃœTÃœPHANELER ---
try:
    import docx 
    import pytesseract
    from PIL import Image
    import pdfplumber
except ImportError:
    pass

from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_openai import ChatOpenAI, OpenAIEmbeddings 
from langchain_core.prompts import PromptTemplate 
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import FAISS 
from langchain_core.documents import Document 

pytesseract.pytesseract.tesseract_cmd = '/opt/homebrew/bin/tesseract'

# --- API AYARLARI ---
class MatchResult(BaseModel):
    job_title: str
    general_score: float
    skill_match: float
    experience_match: float
    report_summary: str

app = FastAPI(title="Hibrit LLM CV EÅŸleÅŸtirme API'si (Final)")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ====================================================================
# 1. VERÄ° YÃœKLEME VE VEKTÃ–R Ä°NDEKSÄ° (FAISS)
# ====================================================================

embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")
GLOBAL_RETRIEVER = None
ALL_JOB_DATA = []

def load_data(file_name):
    try:
        with open(file_name, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"KRÄ°TÄ°K HATA: {file_name} dosyasÄ± bulunamadÄ±.")
        return [] 

def initialize_vector_store():
    global GLOBAL_RETRIEVER, ALL_JOB_DATA
    ALL_JOB_DATA = load_data('parsed_jobs_FINAL.json')
    if not ALL_JOB_DATA: return

    job_docs = []
    for job in ALL_JOB_DATA:
        weighted_content = (
            f"Pozisyon: {job['job_title']} " * 3 +
            f"SektÃ¶r: {job['sector']} " * 2 +
            f"Detaylar: {job.get('description', '')} {job.get('qualifications_raw', '')}"
        )
        job_docs.append(Document(page_content=weighted_content, metadata={"job_title": job['job_title']}))

    if job_docs:
        vector_store = FAISS.from_documents(job_docs, embedding_model)
        GLOBAL_RETRIEVER = vector_store.as_retriever(search_kwargs={"k": 100}) 
        print(f"INFO: FAISS VektÃ¶r Ä°ndeksi {len(job_docs)} ilan ile hazÄ±rlandÄ±.")

initialize_vector_store()

# ====================================================================
# 2. HAFTA 4: PARSING, TEMÄ°ZLEME VE NORMALÄ°ZASYON
# ====================================================================

def clean_text(text: str) -> str:
    """Metin temizleme: BoÅŸluklar ve anlamsÄ±z karakterler."""
    if not text: return ""
    text = re.sub(r'[\r\n\t]+', ' ', text) # SatÄ±r sonlarÄ±nÄ± boÅŸluÄŸa Ã§evir
    text = re.sub(r'\s+', ' ', text)       # Ã‡ift boÅŸluklarÄ± tek boÅŸluÄŸa indir
    return text.strip()

def normalize_titles(text: str) -> str:
    """BÃ¶lÃ¼m ve unvan normalizasyonu."""
    replacements = {
        r'end\.?\s*mÃ¼h\.?': 'EndÃ¼stri MÃ¼hendisliÄŸi',
        r'bil\.?\s*mÃ¼h\.?': 'Bilgisayar MÃ¼hendisliÄŸi',
        r'mak\.?\s*mÃ¼h\.?': 'Makine MÃ¼hendisliÄŸi',
        r'yazÄ±lÄ±m uzm\.?': 'YazÄ±lÄ±m UzmanÄ±',
        r'ik': 'Ä°nsan KaynaklarÄ±'
    }
    text_lower = text.lower()
    for pattern, replacement in replacements.items():
        if re.search(pattern, text_lower):
            return replacement # Tam deÄŸiÅŸim yapÄ±yoruz ki net olsun
    return text

def calculate_experience_duration(text: str) -> float:
    """Metindeki tarih aralÄ±klarÄ±nÄ± bulup toplam deneyim yÄ±lÄ±nÄ± hesaplar."""
    year_pattern = re.findall(r'(\d{4})\s*-\s*(\d{4}|Devam|Halen|Present)', text)
    total_years = 0.0
    current_year = datetime.now().year
    
    for start, end in year_pattern:
        try:
            start_year = int(start)
            end_year = current_year if end in ['Devam', 'Halen', 'Present'] else int(end)
            diff = end_year - start_year
            if diff >= 0: total_years += diff
        except: continue
            
    if total_years == 0:
        text_year_match = re.search(r'(\d+)\s*(?:yÄ±l|sene|year)', text.lower())
        if text_year_match: total_years = float(text_year_match.group(1))

    return total_years

def validate_is_real_cv(text_content: str) -> bool:
    """DosyanÄ±n CV olup olmadÄ±ÄŸÄ±nÄ± kontrol eder (KapÄ± BekÃ§isi)."""
    if len(text_content) < 50: return False
    
    keywords = ["eÄŸitim", "deneyim", "iÅŸ", "yetenekler", "beceriler", "education", "experience", "skills", "Ã¶zgeÃ§miÅŸ", "cv", "iletiÅŸim", "university", "lise", "lisans"]
    found = [k for k in keywords if k in text_content.lower()]
    
    # En az 3 anahtar kelime geÃ§meli
    if len(found) >= 3: return True
    
    # Emin olamazsak LLM'e soralÄ±m
    try:
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.0)
        prompt = f"Bu metin bir CV (Ã–zgeÃ§miÅŸ) mi? Sadece 'EVET' veya 'HAYIR' yaz.\n\nMetin: {text_content[:500]}"
        res = llm.invoke(prompt).content.strip().upper()
        return "EVET" in res
    except: return True

def parse_cv_content(file_path):
    """Dosyadan metin okur (GeliÅŸmiÅŸ OCR DesteÄŸi)."""
    pytesseract.pytesseract.tesseract_cmd = '/opt/homebrew/bin/tesseract'
    ext = os.path.splitext(file_path)[1].lower()
    text = ""
    
    try:
        if ext == '.pdf':
            with pdfplumber.open(file_path) as pdf:
                for page in pdf.pages:
                    if page.extract_text(): text += page.extract_text() + "\n"
                    
        elif ext == '.docx':
            doc = docx.Document(file_path)
            text = "\n".join([p.text for p in doc.paragraphs])
            
        elif ext in ['.png', '.jpg', '.jpeg']:
            image = Image.open(file_path)
            
            # --- GELÄ°ÅžMÄ°Åž OCR AYARI ---
            # --psm 6: SayfayÄ± tek bir metin bloÄŸu olarak gÃ¶r (SÃ¼tunlarÄ± karÄ±ÅŸtÄ±rmayÄ± engeller)
            # lang='tur+eng': TÃ¼rkÃ§e ve Ä°ngilizce karakterleri tanÄ±
            try:
                # Ã–nce Tesseract'Ä±n yolunu kontrol etmeye gerek yok, sistem yolunda olmalÄ±.
                text = pytesseract.image_to_string(image, lang='tur+eng', config='--psm 6')
            except Exception as ocr_error:
                print(f"OCR HatasÄ± (Tesseract YÃ¼klÃ¼ mÃ¼?): {ocr_error}")
                # Yedek: Sadece Ä°ngilizce dene (Bazen TÃ¼rkÃ§e paketi olmayabilir)
                text = pytesseract.image_to_string(image, lang='eng', config='--psm 6')

            print(f"INFO: OCR tamamlandÄ±. Okunan karakter sayÄ±sÄ±: {len(text)}")
            
        else: 
            with open(file_path, 'r', encoding='utf-8') as f: return f.read()
            
    except Exception as e:
        print(f"Genel Parse HatasÄ±: {e}")
        return ""
    
    # Temizlik
    return re.sub(r'\s+', ' ', text).strip()

# ====================================================================
# 3. SKORLAMA MANTIÄžI (AÄžIRLIKLAR + CEZA)
# ====================================================================

def map_education_level(level_str):
    level_str = str(level_str).lower()
    if "doktora" in level_str: return 5
    if "yÃ¼ksek lisans" in level_str: return 4
    if "Ã¼niversite" in level_str or "lisans" in level_str or "bachelor" in level_str or "mÃ¼hendis" in level_str: return 3
    if "Ã¶n lisans" in level_str or "myo" in level_str: return 2
    if "lise" in level_str: return 1
    return 0

def calculate_rule_scores(query_cv, job_details):
    cv_lvl = map_education_level(query_cv.get('education_raw', ''))
    job_lvl = map_education_level(job_details.get('education_level', ''))
    s_edu = 1.0 if cv_lvl >= job_lvl else (0.5 if cv_lvl == job_lvl - 1 else 0.0)

    s_loc = 0.5 
    cv_loc = query_cv.get('location', '').lower()
    job_loc = job_details.get('location', '').lower()
    if cv_loc and job_loc:
        if cv_loc.split(',')[0] in job_loc: s_loc = 1.0
        elif "istanbul" in cv_loc and "istanbul" in job_loc: s_loc = 1.0

    s_sal = 1.0 if "uzman" in job_details['job_title'].lower() or "mÃ¼hendis" in job_details['job_title'].lower() else 0.5
    
    return s_edu, s_loc, s_sal

def is_field_mismatch(cv_edu, job_title):
    """MÃ¼hendisi garson yapmayÄ± engelleyen PYTHON KURALI."""
    cv_edu = cv_edu.lower()
    job_title = job_title.lower()
    
    if "mÃ¼hendis" in cv_edu:
        allowed = ["mÃ¼hendis", "yazÄ±lÄ±m", "software", "developer", "geliÅŸtirici", "uzman", "analist", "teknik", "ar-ge", "bilim"]
        if any(k in job_title for k in allowed): return False 
        
        banned = ["garson", "temizlik", "bellboy", "steward", "ÅŸofÃ¶r", "kasiyer", "satÄ±ÅŸ danÄ±ÅŸmanÄ±", "resepsiyonist"]
        if any(k in job_title for k in banned): return True 

    return False

# ====================================================================
# 4. LLM RERANKING
# ====================================================================

def rank_with_llm_logic(query_cv, job_list):
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.0) 
    
    # ðŸ‘‡ DÃœZELTME: Prompt'a "MÃ¼hendislik = YazÄ±lÄ±m" kuralÄ±nÄ± sert bir ÅŸekilde ekledik.
    prompt = PromptTemplate.from_template("""
    Sen Teknik Bir Ä°ÅŸe AlÄ±m UzmanÄ±sÄ±n. AÅŸaÄŸÄ±daki adayÄ± iÅŸ ilanÄ±yla karÅŸÄ±laÅŸtÄ±r.
    
    ADAY BÃ–LÃœMÃœ: {cv_edu}
    ADAY YETKÄ°NLÄ°KLERÄ°: {cv_text}
    
    Ä°LAN BAÅžLIÄžI: {job_title}
    Ä°LAN DETAYI: {job_desc}
    
    --- KRÄ°TÄ°K EÅžLEÅžTÄ°RME KURALLARI ---
    1. **MÃœHENDÄ°SLÄ°K KURALI:** EÄŸer aday "Bilgisayar MÃ¼hendisliÄŸi", "YazÄ±lÄ±m MÃ¼hendisliÄŸi" veya "BiliÅŸim" mezunuysa; "YazÄ±lÄ±m UzmanÄ±", "Developer", "GeliÅŸtirici", "Tester", "Analist", "Engineer" ilanlarÄ± ile **%100 AYNI ALANDADIR.** Asla alan uyuÅŸmazlÄ±ÄŸÄ± deme!
    
    2. **PUANLAMA (0-10):**
       - Alan/BÃ¶lÃ¼m tutuyorsa (YukarÄ±daki kural): **En az 7 Puan** ver.
       - Alan tutuyor ama tecrÃ¼be eksikse (Junior vs Senior): **6 Puan** ver.
       - Alan tamamen alakasÄ±zsa (Ã–rn: MÃ¼hendis -> Garson): **0 Puan** ver.

    3. **RAPORLAMA:** - EÄŸer puanÄ± kÄ±rdÄ±ysan sebebini "TecrÃ¼be eksikliÄŸi" veya "Teknik yetkinlik eksikliÄŸi" olarak belirt. "Alan uyuÅŸmazlÄ±ÄŸÄ±" deme.
    
    JSON Ã‡IKTISI VER: 
    {{ "uyum_skoru": [PUAN], "analiz_ozeti": "[KISA VE MANTIKLI AÃ‡IKLAMA]" }}
    """)
    
    reranked = []
    chain = prompt | llm | StrOutputParser()
    
    # Ä°lk 15 ilanÄ± analiz et
    for job in job_list[:15]: 
        
        cv_text_short = (query_cv.get('experience_raw', '') + " " + query_cv.get('skills_raw', ''))[:500]
        
        try:
            response = chain.invoke({
                "cv_edu": query_cv.get('education_raw', 'BelirtilmemiÅŸ'),
                "cv_text": cv_text_short,
                "job_title": job['job_title'],
                "job_desc": job.get('description', '')[:300]
            })
            
            match = re.search(r'\{.*\}', response, re.DOTALL)
            if match:
                data = json.loads(match.group(0))
                llm_score = float(data.get('uyum_skoru', 0))
                reason = data.get('analiz_ozeti', 'Analiz edildi.')
            else:
                llm_score = 0; reason = "LLM YanÄ±t HatasÄ±"
                
        except Exception as e:
            # print(f"LLM HatasÄ± ({job['job_title']}): {e}") 
            llm_score = 0; reason = "API HatasÄ±"

        # Python tarafÄ±nda ekstra gÃ¼venlik (MÃ¼hendis -> YazÄ±lÄ±m UzmanÄ± eÅŸleÅŸmesini garantiye al)
        if "bilgisayar" in query_cv.get('education_raw', '').lower() and "yazÄ±lÄ±m" in job['job_title'].lower():
            if llm_score < 5: # EÄŸer LLM hata yapÄ±p dÃ¼ÅŸÃ¼k verdiyse dÃ¼zelt
                llm_score = 7.0
                reason = "BÃ¶lÃ¼m ve pozisyon teknik olarak uyumlu (Otomatik DÃ¼zeltme)."

        # Alan UyuÅŸmazlÄ±ÄŸÄ± KontrolÃ¼ (Sadece gerÃ§ekten alakasÄ±zlar iÃ§in)
        if is_field_mismatch(query_cv.get('education_raw', ''), job['job_title']):
            llm_score = 0.0
            reason = f"ALAN UYUÅžMAZLIÄžI: {query_cv.get('education_raw')} -> {job['job_title']}"

        # Final Skor Hesapla
        s_edu, s_loc, s_sal = calculate_rule_scores(query_cv, job)
        final_score = (0.6 * (llm_score/10)) + (0.1 * s_edu) + (0.1 * s_loc) + (0.2 * s_sal)
        
        reranked.append({
            "job_title": job['job_title'],
            "general_score": final_score,
            "skill_match": llm_score / 10, 
            "experience_match": s_edu, 
            "report_summary": reason
        })
        
    reranked.sort(key=lambda x: x['general_score'], reverse=True)
    return reranked[:5]

# ====================================================================
# 5. API ENDPOINT
# ====================================================================

def quick_llm_parse(text):
    """CV'den Bilgi Ã‡ekme"""
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.0)
    prompt = """AÅŸaÄŸÄ±daki CV metnini analiz et ve JSON formatÄ±nda bilgileri Ã§Ä±kar:
    { "name": "Ad Soyad", "education_raw": "BÃ¶lÃ¼m/EÄŸitim (Ã–rn: Bilgisayar MÃ¼hendisliÄŸi)", "location": "Åžehir" }
    Metin: """ + text[:1500]
    
    try:
        res = llm.invoke(prompt).content
        match = re.search(r'\{.*\}', res, re.DOTALL)
        if match: return json.loads(match.group(0))
    except: pass
    return {"name": "Aday", "education_raw": "BelirtilmemiÅŸ", "location": "Ä°stanbul"}

@app.post("/api/match_cv", response_model=List[MatchResult])
async def match_cv(file: UploadFile = File(...)):
    with NamedTemporaryFile(delete=False, suffix=f".{file.filename.split('.')[-1]}") as temp:
        temp.write(await file.read())
        temp_path = temp.name

    # 1. Parsing & Temizleme
    cv_text = parse_cv_content(temp_path)
    os.remove(temp_path)
    
    cv_text = clean_text(cv_text) # Temizleme fonksiyonu
    
    if not cv_text.strip():
        raise HTTPException(status_code=400, detail="Dosya boÅŸ veya okunamadÄ±.")

    # 2. Validasyon (CV mi?)
    if not validate_is_real_cv(cv_text):
        raise HTTPException(status_code=400, detail="Bu dosya bir CV'ye benzemiyor.")

    # 3. Bilgi Ã‡Ä±karÄ±mÄ± ve Normalizasyon
    cv_data = quick_llm_parse(cv_text)
    
    # NormalizasyonlarÄ± Uygula
    cv_data['education_raw'] = normalize_titles(cv_data.get('education_raw', ''))
    cv_data['experience_years'] = calculate_experience_duration(cv_text)
    
    cv_data['text'] = cv_text 
    cv_data['experience_raw'] = cv_text 
    cv_data['skills_raw'] = cv_text

    print(f"\n---> Ä°ÅžLENEN CV: {cv_data.get('education_raw')} | SÃ¼re: {cv_data.get('experience_years')} YÄ±l")

    # 4. Arama ve SÄ±ralama (Keyword Rescue + FAISS)
    candidate_jobs = []
    
    # Keyword Rescue (MÃ¼hendis KorumasÄ±)
    keywords = ["yazÄ±lÄ±m", "software", "developer", "mÃ¼hendis", "bilgisayar", "biliÅŸim"]
    cv_lower = cv_text.lower()
    
    if any(k in cv_lower for k in keywords):
        for job in ALL_JOB_DATA:
            job_str = (job['job_title'] + " " + job['sector']).lower()
            if any(k in job_str for k in keywords):
                if job not in candidate_jobs: candidate_jobs.append(job)

    # FAISS (Ek olarak)
    if GLOBAL_RETRIEVER:
        query = f"{cv_data['education_raw']} {cv_text[:500]}"
        relevant_docs = GLOBAL_RETRIEVER.invoke(query) 
        relevant_titles = [doc.metadata['job_title'] for doc in relevant_docs]
        for title in relevant_titles:
            job = next((j for j in ALL_JOB_DATA if j['job_title'] == title), None)
            if job and job not in candidate_jobs:
                candidate_jobs.append(job)

    if len(candidate_jobs) < 5: candidate_jobs = ALL_JOB_DATA

    final_results = rank_with_llm_logic(cv_data, candidate_jobs)
    
    return final_results

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)