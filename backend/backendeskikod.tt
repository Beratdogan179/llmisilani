# import os
# import io
# import time
# import json
# from tempfile import NamedTemporaryFile
# from fastapi import FastAPI, File, UploadFile, HTTPException
# from fastapi.middleware.cors import CORSMiddleware
# from pydantic import BaseModel

# # --- LANGCHAIN STABIL İMPORTLAR ---
# # Hata veren 'langchain.text_splitter' sorununu çözen doğru import yolu:
# from langchain_community.document_loaders import PyPDFLoader, TextLoader # Dosya okuyucular
# from langchain_openai import ChatOpenAI, OpenAIEmbeddings 
# from langchain_core.prompts import ChatPromptTemplate 
# from langchain_core.runnables import RunnablePassthrough
# from langchain_core.output_parsers import JsonOutputParser 
# from langchain_text_splitters import RecursiveCharacterTextSplitter # DOĞRU YOL!
# from langchain_community.vectorstores import FAISS

# # --- Pydantic Modelleri (Frontend'e Dönen Veri Şeması) ---
# class MatchResult(BaseModel):
#     # Frontend'deki MatchResult interface'i ile aynı olmalıdır.
#     job_title: str
#     general_score: float
#     skill_match: float
#     experience_match: float
#     report_summary: str

# # --- FastAPI Uygulama Kurulumu ---
# app = FastAPI(title="LLM Aday Eşleştirme API'si")

# # CORS ayarları: Frontend'in (localhost:3000) erişimi için
# origins = [ "http://localhost", "http://localhost:3000" ]
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=origins,
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# # --- LLM ve Vektör Veritabanı Kurulumu ---
# try:
#     # LLM Modeli: gpt-3.5-turbo kullanılıyor.
#     llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.1) 
#     embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

#     # Mock İş İlanları Verisi (Veritabanını oluşturmak için)
#     MOCK_JOB_ADS = [
#         "İlan Başlığı: Kıdemli Python Geliştiricisi\nGereksinimler: Minimum 5 yıl tecrübe, FastAPI, PostgreSQL, AWS Cloud bilgisi. Takım liderliği deneyimi tercih sebebidir.",
#         "İlan Başlığı: Veri Analisti\nGereksinimler: İstatistik, SQL ve Python Pandas bilgisi. R dili ve Power BI tecrübesi zorunludur. Deneyim: 3 yıl.",
#         "İlan Başlığı: Mobil Uygulama Geliştiricisi\nGereksinimler: Flutter veya React Native tecrübesi. Backend bilgisi önemsizdir. UI/UX bilgisi beklenir.",
#     ]

#     # Vektör Veritabanı Oluşturma
#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
#     all_chunks = text_splitter.create_documents([MOCK_JOB_ADS[0], MOCK_JOB_ADS[1], MOCK_JOB_ADS[2]])
    
#     vector_store = FAISS.from_documents(all_chunks, embedding_model)
#     retriever = vector_store.as_retriever()
    
# except Exception as e:
#     print(f"HATA: LLM veya Embeddings kurulumunda sorun: {e}")
#     llm = None
#     retriever = None

# # 2. LLM Prompt Şablonu (RAG için)
# prompt_template = """
# You are an AI analyst that matches the candidate's CV with the job ads. 
# Your task is to compare the CV content with the JOB ADS provided below.

# 1. Scoring: Calculate compatibility scores (from 0.0 to 1.0) for General, Skill, and Experience match for EACH job ad.
# 2. Summary: Create a short HR report summary listing advantages and disadvantages for the candidate regarding that job.

# CV CONTENT:
# ---
# {cv_content}
# ---

# JOB ADS (Analyze ONLY these ads):
# ---
# {context}
# ---

# Please return the result ONLY in a valid JSON format. The JSON structure must be an array containing an object for each job ad. DO NOT include any text outside the JSON array (e.g., '```json').
# """
# PROMPT = ChatPromptTemplate.from_template(prompt_template)


# # --- Yardımcı Fonksiyonlar ---

# def parse_document(file: UploadFile):
#     """Yüklenen dosyayı okur ve metin içeriğini döndürür."""
#     with NamedTemporaryFile(delete=False, suffix=f".{file.filename.split('.')[-1]}") as temp_file:
#         file_content = file.file.read()
#         temp_file.write(file_content)
#         temp_path = temp_file.name

#     text_content = ""
#     try:
#         file_extension = temp_path.split('.')[-1].lower()

#         if file_extension == 'pdf':
#             loader = PyPDFLoader(temp_path)
#         elif file_extension in ['txt']:
#             loader = TextLoader(temp_path, encoding='utf-8')
#         elif file_extension in ['docx']:
#             return "Dosya okuma hatası: DOCX formatı desteklenmiyor. Lütfen PDF veya TXT kullanın."
#         else:
#             raise ValueError("Desteklenmeyen dosya formatı.")
        
#         documents = loader.load()
#         text_content = "\n\n".join(doc.page_content for doc in documents)

#     except Exception as e:
#         print(f"HATA: Dosya okunamadı: {e}")
#         text_content = "Dosya okuma hatası: Lütfen dosya formatını kontrol edin."
#     finally:
#         os.remove(temp_path)
    
#     return text_content

# def format_docs(docs):
#     """RAG için çekilen belgeleri tek metin olarak formatlar."""
#     return "\n\n---\n\n".join(doc.page_content for doc in docs)

# # --- API Endpoint'leri ---

# @app.get("/")
# def read_root():
#     return {"message": "LLM Eşleştirme API'si çalışıyor."}


# @app.post("/api/match_cv", response_model=list[MatchResult])
# async def match_cv(file: UploadFile = File(...)):
#     if not llm or not retriever:
#         raise HTTPException(status_code=503, detail="LLM servisi kullanıma hazır değil. Lütfen API anahtarını kontrol edin.")
        
#     start_time = time.time()
    
#     # 1. CV'yi metne çevirme
#     cv_text = parse_document(file)
#     if "Dosya okuma hatası" in cv_text:
#         raise HTTPException(status_code=400, detail=cv_text)
        
#     # 2. RAG Zincirini Çalıştırma
#     relevant_jobs = retriever.invoke(cv_text)
#     # 3. LLM'den Analiz İsteme
#     rag_chain = (
#         {"context": lambda x: format_docs(x['relevant_jobs']), "cv_content": lambda x: x['cv_content']}
#         | PROMPT
#         | llm
#         | JsonOutputParser(pydantic_object=MatchResult)
#     )
    
#     try:
#         results = rag_chain.invoke({
#             "relevant_jobs": relevant_jobs, 
#             "cv_content": cv_text
#         })
        
#         if not isinstance(results, list):
#             results = [results] 
        
#         validated_results = [MatchResult(**res) for res in results]
        
#     except Exception as e:
#         print(f"LLM Çıktısı Hatası: {e}")
#         raise HTTPException(status_code=500, detail="LLM'den geçerli JSON alınamadı veya format hatası.")

#     end_time = time.time()
#     print(f"INFO: Eşleştirme süresi: {end_time - start_time:.2f} saniye")
    
#     return validated_results